{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import urllib\n",
    "# BS4\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Scrapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1 Define the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL LINK\n",
    "start_URL = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "\n",
    "# TARGET Link\n",
    "target_URL= \"https://en.wikipedia.org/wiki/Philosophy\"\n",
    "\n",
    "# store data from start link \n",
    "called_urls = [start_URL]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2 Getting Data ( Scraping )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_method(pass_url):\n",
    "    # Define parameters\n",
    "    response = requests.get(pass_url)  # get requests from pass_url\n",
    "    html = response.text  # text from response\n",
    "    soup = BeautifulSoup(html, \"html.parser\")  # initilaize soup from BS4\n",
    "    # declare get_content to get the body of URL\n",
    "    body_content = soup.find(id=\"mw-content-text\").find(class_=\"mw-parser-output\")\n",
    "    # if the link have no links return None\n",
    "    article_link = None\n",
    "    # Find all paraghraps in all divs in body_content\n",
    "    for element in body_content.find_all(\"p\", recursive=False):\n",
    "        #find all divs into body_content\n",
    "        if element.find(\"a\", recursive=False):\n",
    "            # article link -> \"a\"\n",
    "            article_link = element.find(\"a\", recursive=False).get('href')\n",
    "            break\n",
    "    # Other case Not article\n",
    "    if not article_link:\n",
    "        return\n",
    "    # full_link for link wikipedia + the article link\n",
    "    full_link = urllib.parse.urljoin(\n",
    "        'https://en.wikipedia.org/', article_link)\n",
    "    \n",
    "    return full_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2 Conditions on scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(scraping_history, target_URL, max_steps=30):\n",
    "    # At philosphy\n",
    "    if scraping_history[-1] == target_URL:\n",
    "        print(\"Target 'Philosphy' done\")\n",
    "        return False\n",
    "    # max iterations to stop\n",
    "    elif len(scraping_history) > max_steps:\n",
    "        print(\"Max number of search is 30, so its interrupted\")\n",
    "        return False\n",
    "    # LOOP infinite\n",
    "    elif scraping_history[-1] in scraping_history[:-1]:\n",
    "        print(\"A Loop , interrupted.\")\n",
    "        return False\n",
    "    #Others\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Special:Random\n",
      "https://en.wikipedia.org/wiki/Townships\n",
      "https://en.wikipedia.org/wiki/Australia\n",
      "https://en.wikipedia.org/wiki/Sovereign_state\n",
      "https://en.wikipedia.org/wiki/International_law\n",
      "https://en.wikipedia.org/wiki/Nation\n",
      "https://en.wikipedia.org/wiki/Community\n",
      "https://en.wikipedia.org/wiki/Social_unit\n",
      "https://en.wikipedia.org/wiki/Social_science\n",
      "https://en.wikipedia.org/wiki/Branches_of_science\n",
      "https://en.wikipedia.org/wiki/Empirical\n",
      "https://en.wikipedia.org/wiki/Information\n",
      "https://en.wikipedia.org/wiki/Uncertainty\n",
      "https://en.wikipedia.org/wiki/Epistemic\n",
      "https://en.wikipedia.org/wiki/Greek_language\n",
      "Arrived at an article with no links !\n"
     ]
    }
   ],
   "source": [
    "# Run the scrapping\n",
    "while scraping(called_urls, target_URL):\n",
    "    #print Normal link\n",
    "    print(called_urls[-1])\n",
    "    # Run get_data_method\n",
    "    full_link = get_data_method(called_urls[-1])\n",
    "    # when reach an article with no links\n",
    "    if not full_link:\n",
    "        print(\"Arrived at an article with no links !\")\n",
    "        break\n",
    "    # append in list\n",
    "    called_urls.append(full_link)\n",
    "    # time \n",
    "    time.sleep(0.5)\n",
    "# save all in called_urls that have visited\n",
    "called_urls=[start_URL]\n",
    "#EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
